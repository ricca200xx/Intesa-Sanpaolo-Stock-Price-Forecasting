gbm_model <- GBM(train_values, shock = "exp", nshock = 1, prelimestimates = prelim_gbm)
summary(gbm_model)
ggm_model <- GGM(train_values, prelimestimates = c(m_base, 0.001, 0.01,p_base,q_base), display = FALSE)
summary(ggm_model)
# Selezione AIC e Calcolo MSE per il vincitore
n_diff <- length(diff_train)
aic_bm <- n_diff * log(sum(residuals(bm_model)^2)/n_diff) + 2 * 3
aic_gbm <- n_diff * log(sum(residuals(gbm_model)^2)/n_diff) + 2 * length(gbm_model$pars)
aic_ggm <- n_diff * log(sum(residuals(ggm_model)^2)/n_diff) + 2 * 5
aic_bm
aic_ggm
best_model <- ggm_model
n_train <- length(train)
n_test  <- length(test)
n_total <- n_train + n_test
indici_test <- (n_train + 1):n_total
pred_test_val <- predict(best_model, newx = indici_test)
pred_test <- as.numeric(pred_test_val)
mse_diffusion <- mean((as.numeric(test) - pred_test)^2)
cat("MSE sul Test Set:", mse_diffusion, "\n")
################################################################################
# Phase 6: GAM MODEL
################################################################################
library(gam)
t_train <- 1:length(train)
gam_data_train <- data.frame(y = as.numeric(train), t = t_train)
gam_data_test  <- data.frame(t = (length(train) + 1):n_obs)
gam_1 <- gam(y ~ t, data = gam_data_train)
gam_2 <- gam(y ~ s(t, df=4), data = gam_data_train)
gam_3 <- gam(y ~ s(t, df=10), data = gam_data_train)
aic_gam <- min(AIC(gam_1), AIC(gam_2), AIC(gam_3))
best_gam <- list(gam_1, gam_2, gam_3)[[which.min(c(AIC(gam_1), AIC(gam_2), AIC(gam_3)))]]
# Previsione e MSE
pred_gam_test <- predict(best_gam, newdata = gam_data_test)
mse_gam <- mean((test_actual - as.numeric(pred_gam_test))^2)
################################################################################
# PHASE 7: ARMAX (Auto-ARIMA con Variabile Esogena Revenue)
################################################################################
library(readxl)
# 1. Caricamento e preparazione della variabile esogena (Revenue)
# Carichiamo il file CSV delle revenue
revenue_df <- read_excel("C:/Users/ricky/OneDrive/Desktop/BEFD project/BEFD-project/revenue_apple_qurter.xlsx")
revenue_df$Quarter_Ended <- as.Date(revenue_df$Quarter_Ended)
# Allineamento: dobbiamo mappare le revenue trimestrali sulle date giornaliere di borsa
# Creiamo un dataframe con tutte le date di borsa presenti nel dataset dei prezzi
daily_dates <- data.frame(Date = index(all_price))
# Uniamo i dati: la revenue viene associata alla data di fine trimestre
daily_revenue <- merge(daily_dates, revenue_df[, c("Quarter_Ended", "Revenue")],
by.x = "Date", by.y = "Quarter_Ended", all.x = TRUE)
# Usiamo la tecnica LOCF (Last Observation Carried Forward) per riempire i giorni
# tra un report e l'altro con l'ultimo valore di revenue noto
library(zoo)
daily_revenue$Revenue <- na.locf(daily_revenue$Revenue, na.rm = FALSE)
# Per i giorni iniziali prima del primo dato di bilancio, usiamo il primo valore disponibile (Backfill)
daily_revenue$Revenue <- na.locf(daily_revenue$Revenue, fromLast = TRUE)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1, prelimestimates = prelim_gbm)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1, prelimestimates = prelim_gbm)
# 1. Stima del modello automatico
best_par <- aic.manual(train_set, intord = 1, seasord = 0)
fit_arima <- arima(train_set, order = c(0, 1, 1), method = "ML")
fit_arima <- arima(train_set, order = c(0, 1, 0), method = "ML")
# 2. Diagnostica dei residui
checkresiduals(fit_arima)
# 3. Previsione sul test set
forecast_arima <- forecast(fit_arima, h = length(test))
pred_arima <- as.numeric(forecast_arima$mean)
# 4. Calcolo MSE
mse_arima <- mean((test_actual - pred_arima)^2)
cat("ARIMA AIC:", fit_arima$aic, "\n")
cat("ARIMA MSE:", mse_arima, "\n")
################################################################################
# Phase 4: Prophet Model
################################################################################
library(prophet)
df_prophet <- data.frame(ds = index(train), y  = as.numeric(train))
################################################################################
# PHASE 7: ARMAX (Auto-ARIMA con Variabile Esogena Revenue)
################################################################################
library(readxl)
# 1. Caricamento e preparazione della variabile esogena (Revenue)
# Carichiamo il file CSV delle revenue
revenue_df <- read_excel("C:/Users/ricky/OneDrive/Desktop/BEFD project/BEFD-project/revenue_apple_qurter.xlsx")
revenue_df$Quarter_Ended <- as.Date(revenue_df$Quarter_Ended)
# Allineamento: dobbiamo mappare le revenue trimestrali sulle date giornaliere di borsa
# Creiamo un dataframe con tutte le date di borsa presenti nel dataset dei prezzi
daily_dates <- data.frame(Date = index(all_price))
# Uniamo i dati: la revenue viene associata alla data di fine trimestre
daily_revenue <- merge(daily_dates, revenue_df[, c("Quarter_Ended", "Revenue")],
by.x = "Date", by.y = "Quarter_Ended", all.x = TRUE)
# Usiamo la tecnica LOCF (Last Observation Carried Forward) per riempire i giorni
# tra un report e l'altro con l'ultimo valore di revenue noto
library(zoo)
daily_revenue$Revenue <- na.locf(daily_revenue$Revenue, na.rm = FALSE)
# Per i giorni iniziali prima del primo dato di bilancio, usiamo il primo valore disponibile (Backfill)
daily_revenue$Revenue <- na.locf(daily_revenue$Revenue, fromLast = TRUE)
################################################################################
# PHASE 7: ARMAX (Auto-ARIMA con Variabile Esogena Revenue)
################################################################################
library(readxl)
# 1. Caricamento e preparazione della variabile esogena (Revenue)
# Carichiamo il file CSV delle revenue
revenue_df <- read_excel("C:/Users/ricky/OneDrive/Desktop/BEFD project/BEFD-project/revenue_apple_qurter.xlsx")
revenue_df$Quarter_Ended <- as.Date(revenue_df$Quarter_Ended)
# Allineamento: creiamo un dataframe con le date di borsa
daily_dates <- data.frame(Date = index(all_price))
# FIX: Usiamo all = TRUE per includere le date dei bilanci anche se sono weekend
# Questo permette di avere i valori di Revenue nel dataset prima del riempimento
daily_revenue_full <- merge(daily_dates, revenue_df[, c("Quarter_Ended", "Revenue")],
by.x = "Date", by.y = "Quarter_Ended", all = TRUE)
# Riempimento dei valori (LOCF - Last Observation Carried Forward)
library(zoo)
# Prima riempiamo in avanti (per i giorni dopo il bilancio)
daily_revenue_full$Revenue <- na.locf(daily_revenue_full$Revenue, na.rm = FALSE)
# Poi riempiamo all'indietro (per coprire i giorni iniziali del 2021)
daily_revenue_full$Revenue <- na.locf(daily_revenue_full$Revenue, fromLast = TRUE)
# Adesso filtriamo il dataset per mantenere SOLO le date in cui la borsa era aperta
daily_revenue <- daily_revenue_full[daily_revenue_full$Date %in% daily_dates$Date, ]
# Creazione della matrice xreg (deve avere lo stesso numero di righe di all_price)
xreg_full <- as.matrix(daily_revenue$Revenue)
colnames(xreg_full) <- "Revenue"
# Divisione della xreg in Train e Test (usando n_train calcolato in precedenza)
n_train <- length(train)
n_obs <- length(all_price)
xreg_train <- xreg_full[1:n_train, , drop = FALSE]
xreg_test  <- xreg_full[(n_train + 1):n_obs, , drop = FALSE]
# 2. Fit del modello ARMAX
library(forecast)
# Inseriamo la xreg nel modello auto.arima
armax_model <- auto.arima(train, xreg = xreg_train)
################################################################################
# PHASE 7: ARMAX (Auto-ARIMA con Variabile Esogena Revenue)
################################################################################
library(readxl)
# 1. Caricamento e preparazione della variabile esogena (Revenue)
# Carichiamo il file CSV delle revenue
revenue_df <- read_excel("C:/Users/ricky/OneDrive/Desktop/BEFD project/BEFD-project/revenue_apple_qurter.xlsx")
revenue_df$Quarter_Ended <- as.Date(revenue_df$Quarter_Ended)
# Assicuriamoci che Revenue sia numerico (rimuovendo eventuali virgole o simboli se presenti)
revenue_df$Revenue <- as.numeric(gsub("[^0-9.]", "", revenue_df$Revenue))
# 2. Allineamento con le date di borsa
daily_dates <- data.frame(Date = index(all_price))
daily_revenue_full <- merge(daily_dates, revenue_df[, c("Quarter_Ended", "Revenue")],
by.x = "Date", by.y = "Quarter_Ended", all = TRUE)
# Riempimento dei valori mancanti (fondamentale per ARMAX)
library(zoo)
daily_revenue_full$Revenue <- na.locf(daily_revenue_full$Revenue, na.rm = FALSE)
daily_revenue_full$Revenue <- na.locf(daily_revenue_full$Revenue, fromLast = TRUE)
# Filtriamo solo per i giorni di borsa aperta
daily_revenue <- daily_revenue_full[daily_revenue_full$Date %in% daily_dates$Date, ]
# 3. CREAZIONE MATRICE XREG (Risoluzione Errore)
# Forziamo la creazione di una matrice numerica pura
xreg_full <- matrix(as.numeric(daily_revenue$Revenue), ncol = 1)
colnames(xreg_full) <- "Revenue"
# Divisione Train/Test
n_train <- length(train)
xreg_train <- xreg_full[1:n_train, , drop = FALSE]
xreg_test  <- xreg_full[(n_train + 1):nrow(xreg_full), , drop = FALSE]
# 4. Fit del modello ARMAX
# Adesso xreg_train è una matrice numerica garantita
library(forecast)
armax_model <- auto.arima(train, xreg = xreg_train)
# 5. Analisi Statistica
summary(armax_model)
coef_armax <- coef(armax_model)
se_armax   <- sqrt(diag(vcov(armax_model)))
# P-value per verificare se le Revenue "spostano" il prezzo
p_val_revenue <- 2 * (1 - pnorm(abs(coef_armax["Revenue"] / se_armax["Revenue"])))
cat("\nP-value della variabile Revenue:", p_val_revenue)
# 6. Previsione e MSE
pred_armax_obj <- forecast(armax_model, xreg = xreg_test)
pred_armax_test <- as.numeric(pred_armax_obj$mean)
mse_armax <- mean((as.numeric(test) - pred_armax_test)^2)
cat("\nAIC ARMAX:", armax_model$aic)
cat("\nMSE ARMAX:", mse_armax)
cat("ARIMA AIC:", fit_arima$aic, "\n")
cat("ARIMA MSE:", mse_arima, "\n")
################################################################################
# Phase 6: GAM MODEL
################################################################################
library(gam)
t_train <- 1:length(train)
gam_data_train <- data.frame(y = as.numeric(train), t = t_train)
gam_data_test  <- data.frame(t = (length(train) + 1):n_obs)
gam_1 <- gam(y ~ t, data = gam_data_train)
gam_2 <- gam(y ~ s(t, df=4), data = gam_data_train)
gam_3 <- gam(y ~ s(t, df=10), data = gam_data_train)
aic_gam <- min(AIC(gam_1), AIC(gam_2), AIC(gam_3))
best_gam <- list(gam_1, gam_2, gam_3)[[which.min(c(AIC(gam_1), AIC(gam_2), AIC(gam_3)))]]
# Previsione e MSE
pred_gam_test <- predict(best_gam, newdata = gam_data_test)
mse_gam <- mean((test_actual - as.numeric(pred_gam_test))^2)
modelli_nomi <- c("Auto-ARIMA", "Prophet", "Diffusion (Best)", "GAM (Best)")
aic_valori   <- c(fit_arima$aic, aic_prophet, best_aic_diff, aic_gam)
mse_valori   <- c(mse_arima, mse_prophet, mse_diffusion, mse_gam)
### clearing the global environment
rm(list = ls())
##### temp some function I made in the past that could prove useful #####
aic.manual <- function(myarima, intord = 0, seasord = 0){
##temp notes: the function takes the actual data (time series) and then fits
## the arimas, so the input should NOT be an arima, but rather raw data
aicm <- matrix(0,4,4)
LowestIndex <- 0.0
MAIndex <- 0
ARIndex <- 0
for (i in 0:3) for (j in 0:3) {
fit<-arima(myarima, order = c(i,intord,j),
seasonal = list(order = c(0,seasord,0), period = 12), method = "ML")
aicm[i+1,j+1] <- fit$aic
if (i==0 & j==0) {
LowestIndex <- fit$aic
} else if (LowestIndex>aicm[i+1,j+1])  {
LowestIndex <- fit$aic
ARIndex <- i
MAIndex <- j
}
}
cat("Lowest Index =",LowestIndex, "\n")
cat("AR =",ARIndex, "\n")
cat("MA =",MAIndex, "\n")
rownames(aicm) <- c(0,1,2,3)
colnames(aicm) <- c(0,1,2,3)
aicm
}
int.conf <- function(fit.arima) {
cat("Upper Bound =", fit.arima$coef + (1.96 * diag(fit.arima$var.coef ^ 0.5)), "\n")
cat("Lower Bound =", fit.arima$coef - (1.96 * diag(fit.arima$var.coef ^ 0.5)), "\n")
}
#library requirement
if (!require("quantmod")) install.packages("quantmod")
if (!require("fpp2")) install.packages("fpp2")
if (!require("zoo")) install.packages("zoo")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("forecast")) install.packages("forecast")
if (!require("gam")) install.packages("gam")
if (!require("prophet")) install.packages("prophet")
library(quantmod)
library(zoo)
library(fpp2)
library(gridExtra)
library(urca)
library(forecast)
library(gam)
library(prophet)
symbol <- "AAPL"
data_fine <- as.Date("2026-01-01")
data_inizio <- data_fine - (365 * 5)
# getSymbols scarica automaticamente solo i giorni di borsa aperta
data_raw <- getSymbols(symbol, src = "yahoo", auto.assign = FALSE,
from = data_inizio, to = data_fine)
# Selezioniamo il prezzo rettificato ed eliminiamo eventuali NA residui
all_price <- na.omit(data_raw[, 6])
# Divisione train e test (80/20)
n_obs <- length(all_price)
split_point <- floor(0.8 * n_obs)
train <- all_price[1:split_point]
test  <- all_price[(split_point + 1):n_obs]
# Creazione serie storica con frequenza 252 (Standard finanziario)
# Non usiamo più 365 perché i weekend non esistono in questo dataset
train_set <- ts(as.numeric(train), frequency = 252)
test_set  <- ts(as.numeric(test), frequency = 252)
# Valori reali del test set per calcolo MSE
test_actual <- as.numeric(test)
# Plot dei dati reali (senza segmenti piatti nei weekend)
df_plot <- data.frame(
Data = index(all_price),
price = as.numeric(all_price),
type = c(rep("Train", length(train)), rep("Test", length(test)))
)
ggplot(df_plot, aes(x = Data, y = price, color = type)) +
geom_line(linewidth = 0.5) +
scale_color_manual(values = c("Train" = "#0072B2", "Test" = "#D55E00")) +
labs(title = "Apple Stock (AAPL) - Solo Giorni di Trading",
subtitle = "Frequenza annuale impostata a 252 giorni",
x = "Data", y = "Price Adjusted ($)") +
theme_minimal() +
scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
theme(legend.position = "bottom")
p1 <- autoplot(Acf(train_set, plot = FALSE, lag.max = 60)) +
ggtitle("ACF- Original") + theme_minimal()
p2 <- autoplot(Pacf(train_set, plot = FALSE, lag.max = 60)) +
ggtitle("PACF - Original") + theme_minimal()
grid.arrange(p1, p2)
#differentation of the series
diff_train <- diff(train_set)
p3 <- autoplot(Acf(diff_train, plot = FALSE, lag.max = 60)) +
ggtitle("ACF - Differentition") + theme_minimal()
p4 <- autoplot(Pacf(diff_train, plot = FALSE, lag.max = 60)) +
ggtitle("PACF - Differentition") + theme_minimal()
grid.arrange(p3, p4)
# 1. Stima del modello automatico
best_par <- aic.manual(train_set, intord = 1, seasord = 0)
fit_arima <- arima(train_set, order = c(0, 1, 0), method = "ML")
# 2. Diagnostica dei residui
checkresiduals(fit_arima)
# 3. Previsione sul test set
forecast_arima <- forecast(fit_arima, h = length(test))
pred_arima <- as.numeric(forecast_arima$mean)
# 4. Calcolo MSE
mse_arima <- mean((test_actual - pred_arima)^2)
cat("ARIMA AIC:", fit_arima$aic, "\n")
cat("ARIMA MSE:", mse_arima, "\n")
################################################################################
# Phase 4: Prophet Model
################################################################################
library(prophet)
df_prophet <- data.frame(ds = index(train), y  = as.numeric(train))
m_prophet <- prophet(df_prophet,
daily.seasonality = TRUE,
yearly.seasonality = TRUE,
weekly.seasonality = TRUE)
future <- make_future_dataframe(m_prophet, periods = length(test), freq = "day")
forecast_prophet <- predict(m_prophet, future)
# AIC (calcolo manuale dai residui training)
y_hat_train <- forecast_prophet$yhat[1:nrow(df_prophet)]
residuals_prophet <- df_prophet$y - y_hat_train
rss_prophet <- sum(residuals_prophet^2)
n <- nrow(df_prophet)
k_prophet <- sum(m_prophet$params$delta != 0) + 5
aic_prophet <- n * log(rss_prophet/n) + 2 * k_prophet
# MSE (su test set)
pred_prophet_test <- forecast_prophet$yhat[(n_obs - length(test) + 1):n_obs]
mse_prophet <- mean((test_actual - pred_prophet_test)^2)
################################################################################
# Phase 5: Diffusion Models (DIMORA)
################################################################################
library(DIMORA)
train_values <- as.numeric(train)
bm_model <- BM(train_values, display = FALSE)
summary(bm_model)
m_base <- 8.096008e+04
p_base <- 3.474946e-34
q_base <- 1.121650e+00
prelim_gbm <- c(m_base, p_base, q_base, 504, 630, 0.1)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1, prelimestimates = prelim_gbm)
prelim_gbm <- c(5, 0.0001, 0.02, 504, 630, 0.05)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1, prelimestimates = prelim_gbm)
################################################################################
# Phase 5: Diffusion Models (DIMORA)
################################################################################
library(DIMORA)
train_values <- as.numeric(train)
train_scaled <- as.numeric(train_values) / 100
# 2. PARAMETRI COERENTI:
# Se i prezzi sono ~1.8, il potenziale m deve essere circa 5.0
prelim_safe <- c(5, 0.0001, 0.02, 504, 630, 0.01)
bm_model <- BM(train_scaled, display = FALSE)
summary(bm_model)
prelim_gbm <- c(5, 0.0001, 0.02, 504, 630, 0.05)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1,
prelimestimates = prelim_gbm)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1,
prelimestimates = prelim_safe)
gbm_model <- GBM(train_scaled, shock = "exp", nshock = 1,
prelimestimates = prelim_safe)
bm_model <- BM(train_scaled, display = FALSE)
summary(bm_model)
plot(bm_model)
gbm_model <- GBM(train_scaled, shock = "exp", nshock = 1,
prelimestimates = prelim_safe)
gbm_model <- GBM(train_scaled, shock = "rect", nshock = 1,
prelimestimates = prelim_safe)
gbm_model <- GBM(train_scaled, shock = "rect", nshock = 1,
prelimestimates = prelim_gbm, display = TRUE)
prelim_gbm <- c(5, , 0.01, 0.1, 504, 630, 0.05)
prelim_gbm <- c(5,  0.01, 0.1, 504, 630, 0.05)
gbm_model <- GBM(train_scaled, shock = "rect", nshock = 1,
prelimestimates = prelim_gbm, display = TRUE)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1,
prelimestimates = prelim_gbm)
prelim_gbm <- c(500, 0.0001, 0.02)
gbm_model <- GBM(train_values, prelimestimates = prelim_gbm)
gbm_model <- GBM(train_values, nshock = 0, prelimestimates = prelim_gbm)
summary(gbm_model)
train_values <- as.numeric(train)
bm_model <- BM(train_values, display = FALSE)
summary(bm_model)
m_base <- 8.096008e+04
p_base <- 3.474946e-34
q_base <- 1.121650e+00
prelim_gbm <- c(m_base, p_base, q_base)
gbm_model <- GBM(train_values, nshock = 0, prelimestimates = prelim_gbm)
gbm_model <- GBM(train_values,  prelimestimates = prelim_gbm)
ggm_model <- GGM(train_values, prelimestimates = c(m_base, 0.001, 0.01,p_base,q_base), display = FALSE)
summary(ggm_model)
plot(ggm_model)
library(forecast)
# 1. Creazione dell'oggetto Time Series (Frequenza 252 per borsa aperta)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters
# Usiamo il metodo additivo per la stagionalità (più stabile per i prezzi)
# Se il modello non trova stagionalità, passerà automaticamente a un modello di Holt semplice
hw_model <- hw(train_ts, h = length(test), seasonal = "additive")
# 1. Creazione dell'oggetto Time Series (Frequenza 252 per borsa aperta)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters
# Usiamo il metodo additivo per la stagionalità (più stabile per i prezzi)
# Se il modello non trova stagionalità, passerà automaticamente a un modello di Holt semplice
hw_model <- hw(train_ts, h = length(test), seasonal = "additive")
# 3. Estrazione dei valori fittati (Train) e della previsione (Test)
pred_hw_train <- as.numeric(hw_model$fitted)
################################################################################
# Phase 6: GAM MODEL
# 1. Preparazione Time Series (Frequenza 252)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters (Base R)
# gamma = FALSE esclude la stagionalità se il modello non riesce a calcolarla,
# ma con Apple la lasciamo attiva (gamma = NULL di default)
hw_fit <- HoltWinters(train_ts, seasonal = "additive")
# 3. Previsione per il Test Set
library(forecast)
hw_forecast <- forecast(hw_fit, h = length(test))
# 4. Estrazione Valori
pred_hw_train <- as.numeric(hw_fit$fitted[,1])
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# 5. Calcolo MSE
mse_hw <- mean((as.numeric(test) - pred_hw_test)^2)
cat("\n--- Risultati Holt-Winters ---\n")
cat("MSE Holt-Winters:", mse_hw, "\n")
cat("RMSE Holt-Winters:", sqrt(mse_hw), "\n")
# 6. Preparazione per i grafici
pred_hw_full <- c(pred_hw_train_full, pred_hw_test)
################################################################################
# Phase 6: GAM MODEL
# 1. Preparazione Time Series (Frequenza 252)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters (Base R)
# gamma = FALSE esclude la stagionalità se il modello non riesce a calcolarla,
# ma con Apple la lasciamo attiva (gamma = NULL di default)
hw_fit <- HoltWinters(train_ts, seasonal = "additive")
# 3. Previsione per il Test Set
library(forecast)
hw_forecast <- forecast(hw_fit, h = length(test))
# 4. Estrazione Valori
pred_hw_train <- as.numeric(hw_fit$fitted[,1])
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# 5. Calcolo MSE
mse_hw <- mean((as.numeric(test) - pred_hw_test)^2)
pred_hw_test
################################################################################
# Phase 6: GAM MODEL
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Modello Holt-Winters (Senza stagionalità per massima velocità e stabilità)
# Nota: Spesso sui prezzi azionari il modello solo Trend (gamma=FALSE) performa meglio
hw_fit <- HoltWinters(train_ts, gamma = FALSE)
# 3. Previsione
library(forecast)
hw_for <- forecast(hw_fit, h = length(test))
# 4. GRAFICO VELOCE
plot(hw_for, main="Holt-Winters: Previsione vs Realtà",
col="blue", shadow=TRUE, ylab="Prezzo Apple ($)", xlab="Tempo")
# Aggiungiamo i dati reali sopra (Train + Test)
lines(as.numeric(all_price), col="black", lwd=1)
# Linea verticale che separa Train e Test
abline(v = length(train)/252 + 1, col="red", lty=2)
legend("topleft", legend=c("Prezzo Reale", "Previsione HW", "Intervallo Confidenza"),
col=c("black", "blue", "lightblue"), lwd=2, bty="n")
################################################################################
# Phase 6: GAM MODEL
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Modello Holt-Winters (Senza stagionalità per massima velocità e stabilità)
# Nota: Spesso sui prezzi azionari il modello solo Trend (gamma=FALSE) performa meglio
hw_fit <- HoltWinters(train_ts, gamma = FALSE)
# 3. Previsione
library(forecast)
hw_for <- forecast(hw_fit, h = length(test))
# 4. GRAFICO VELOCE
plot(hw_for, main="Holt-Winters: Previsione vs Realtà",
col="blue", shadow=TRUE, ylab="Prezzo Apple ($)", xlab="Tempo")
# Aggiungiamo i dati reali sopra (Train + Test)
lines(as.numeric(all_price), col="black", lwd=1)
# Linea verticale che separa Train e Test
abline(v = length(train)/252 + 1, col="red", lty=2)
legend("topleft", legend=c("Prezzo Reale", "Previsione HW", "Intervallo Confidenza"),
col=c("black", "blue", "lightblue"), lwd=2, bty="n")
################################################################################
library(gam)
t_train <- 1:length(train)
gam_data_train <- data.frame(y = as.numeric(train), t = t_train)
gam_data_test  <- data.frame(t = (length(train) + 1):n_obs)
################################################################################
# Phase 6: GAM MODEL
# 1. Preparazione Time Series (Frequenza 252)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters (Base R)
# gamma = FALSE esclude la stagionalità se il modello non riesce a calcolarla,
# ma con Apple la lasciamo attiva (gamma = NULL di default)
hw_fit <- HoltWinters(train_ts, seasonal = "additive")
# 3. Previsione per il Test Set
library(forecast)
hw_forecast <- forecast(hw_fit, h = length(test))
# 4. Estrazione Valori
pred_hw_train <- as.numeric(hw_fit$fitted[,1])
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# 5. Calcolo MSE
mse_hw <- mean((as.numeric(test) - pred_hw_test)^2)
cat("\n--- Risultati Holt-Winters ---\n")
cat("MSE Holt-Winters:", mse_hw, "\n")
################################################################################
library(gam)
