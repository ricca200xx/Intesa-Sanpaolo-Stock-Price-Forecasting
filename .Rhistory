ggplot(df_plot, aes(x = Data, y = price, color = type)) +
geom_line(linewidth = 0.5) +
scale_color_manual(values = c("Train" = "#0072B2", "Test" = "#D55E00")) +
labs(title = "Apple Stock (AAPL) - Solo Giorni di Trading",
subtitle = "Frequenza annuale impostata a 252 giorni",
x = "Data", y = "Price Adjusted ($)") +
theme_minimal() +
scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
theme(legend.position = "bottom")
p1 <- autoplot(Acf(train_set, plot = FALSE, lag.max = 60)) +
ggtitle("ACF- Original") + theme_minimal()
p2 <- autoplot(Pacf(train_set, plot = FALSE, lag.max = 60)) +
ggtitle("PACF - Original") + theme_minimal()
grid.arrange(p1, p2)
#differentation of the series
diff_train <- diff(train_set)
p3 <- autoplot(Acf(diff_train, plot = FALSE, lag.max = 60)) +
ggtitle("ACF - Differentition") + theme_minimal()
p4 <- autoplot(Pacf(diff_train, plot = FALSE, lag.max = 60)) +
ggtitle("PACF - Differentition") + theme_minimal()
grid.arrange(p3, p4)
# 1. Stima del modello automatico
best_par <- aic.manual(train_set, intord = 1, seasord = 0)
fit_arima <- arima(train_set, order = c(0, 1, 0), method = "ML")
# 2. Diagnostica dei residui
checkresiduals(fit_arima)
# 3. Previsione sul test set
forecast_arima <- forecast(fit_arima, h = length(test))
pred_arima <- as.numeric(forecast_arima$mean)
# 4. Calcolo MSE
mse_arima <- mean((test_actual - pred_arima)^2)
cat("ARIMA AIC:", fit_arima$aic, "\n")
cat("ARIMA MSE:", mse_arima, "\n")
################################################################################
# Phase 4: Prophet Model
################################################################################
library(prophet)
df_prophet <- data.frame(ds = index(train), y  = as.numeric(train))
m_prophet <- prophet(df_prophet,
daily.seasonality = TRUE,
yearly.seasonality = TRUE,
weekly.seasonality = TRUE)
future <- make_future_dataframe(m_prophet, periods = length(test), freq = "day")
forecast_prophet <- predict(m_prophet, future)
# AIC (calcolo manuale dai residui training)
y_hat_train <- forecast_prophet$yhat[1:nrow(df_prophet)]
residuals_prophet <- df_prophet$y - y_hat_train
rss_prophet <- sum(residuals_prophet^2)
n <- nrow(df_prophet)
k_prophet <- sum(m_prophet$params$delta != 0) + 5
aic_prophet <- n * log(rss_prophet/n) + 2 * k_prophet
# MSE (su test set)
pred_prophet_test <- forecast_prophet$yhat[(n_obs - length(test) + 1):n_obs]
mse_prophet <- mean((test_actual - pred_prophet_test)^2)
################################################################################
# Phase 5: Diffusion Models (DIMORA)
################################################################################
library(DIMORA)
train_values <- as.numeric(train)
bm_model <- BM(train_values, display = FALSE)
summary(bm_model)
m_base <- 8.096008e+04
p_base <- 3.474946e-34
q_base <- 1.121650e+00
prelim_gbm <- c(m_base, p_base, q_base, 504, 630, 0.1)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1, prelimestimates = prelim_gbm)
prelim_gbm <- c(5, 0.0001, 0.02, 504, 630, 0.05)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1, prelimestimates = prelim_gbm)
################################################################################
# Phase 5: Diffusion Models (DIMORA)
################################################################################
library(DIMORA)
train_values <- as.numeric(train)
train_scaled <- as.numeric(train_values) / 100
# 2. PARAMETRI COERENTI:
# Se i prezzi sono ~1.8, il potenziale m deve essere circa 5.0
prelim_safe <- c(5, 0.0001, 0.02, 504, 630, 0.01)
bm_model <- BM(train_scaled, display = FALSE)
summary(bm_model)
prelim_gbm <- c(5, 0.0001, 0.02, 504, 630, 0.05)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1,
prelimestimates = prelim_gbm)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1,
prelimestimates = prelim_safe)
gbm_model <- GBM(train_scaled, shock = "exp", nshock = 1,
prelimestimates = prelim_safe)
bm_model <- BM(train_scaled, display = FALSE)
summary(bm_model)
plot(bm_model)
gbm_model <- GBM(train_scaled, shock = "exp", nshock = 1,
prelimestimates = prelim_safe)
gbm_model <- GBM(train_scaled, shock = "rect", nshock = 1,
prelimestimates = prelim_safe)
gbm_model <- GBM(train_scaled, shock = "rect", nshock = 1,
prelimestimates = prelim_gbm, display = TRUE)
prelim_gbm <- c(5, , 0.01, 0.1, 504, 630, 0.05)
prelim_gbm <- c(5,  0.01, 0.1, 504, 630, 0.05)
gbm_model <- GBM(train_scaled, shock = "rect", nshock = 1,
prelimestimates = prelim_gbm, display = TRUE)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1,
prelimestimates = prelim_gbm)
prelim_gbm <- c(500, 0.0001, 0.02)
gbm_model <- GBM(train_values, prelimestimates = prelim_gbm)
gbm_model <- GBM(train_values, nshock = 0, prelimestimates = prelim_gbm)
summary(gbm_model)
train_values <- as.numeric(train)
bm_model <- BM(train_values, display = FALSE)
summary(bm_model)
m_base <- 8.096008e+04
p_base <- 3.474946e-34
q_base <- 1.121650e+00
prelim_gbm <- c(m_base, p_base, q_base)
gbm_model <- GBM(train_values, nshock = 0, prelimestimates = prelim_gbm)
gbm_model <- GBM(train_values,  prelimestimates = prelim_gbm)
ggm_model <- GGM(train_values, prelimestimates = c(m_base, 0.001, 0.01,p_base,q_base), display = FALSE)
summary(ggm_model)
plot(ggm_model)
library(forecast)
# 1. Creazione dell'oggetto Time Series (Frequenza 252 per borsa aperta)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters
# Usiamo il metodo additivo per la stagionalità (più stabile per i prezzi)
# Se il modello non trova stagionalità, passerà automaticamente a un modello di Holt semplice
hw_model <- hw(train_ts, h = length(test), seasonal = "additive")
# 1. Creazione dell'oggetto Time Series (Frequenza 252 per borsa aperta)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters
# Usiamo il metodo additivo per la stagionalità (più stabile per i prezzi)
# Se il modello non trova stagionalità, passerà automaticamente a un modello di Holt semplice
hw_model <- hw(train_ts, h = length(test), seasonal = "additive")
# 3. Estrazione dei valori fittati (Train) e della previsione (Test)
pred_hw_train <- as.numeric(hw_model$fitted)
################################################################################
# Phase 6: GAM MODEL
# 1. Preparazione Time Series (Frequenza 252)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters (Base R)
# gamma = FALSE esclude la stagionalità se il modello non riesce a calcolarla,
# ma con Apple la lasciamo attiva (gamma = NULL di default)
hw_fit <- HoltWinters(train_ts, seasonal = "additive")
# 3. Previsione per il Test Set
library(forecast)
hw_forecast <- forecast(hw_fit, h = length(test))
# 4. Estrazione Valori
pred_hw_train <- as.numeric(hw_fit$fitted[,1])
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# 5. Calcolo MSE
mse_hw <- mean((as.numeric(test) - pred_hw_test)^2)
cat("\n--- Risultati Holt-Winters ---\n")
cat("MSE Holt-Winters:", mse_hw, "\n")
cat("RMSE Holt-Winters:", sqrt(mse_hw), "\n")
# 6. Preparazione per i grafici
pred_hw_full <- c(pred_hw_train_full, pred_hw_test)
################################################################################
# Phase 6: GAM MODEL
# 1. Preparazione Time Series (Frequenza 252)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters (Base R)
# gamma = FALSE esclude la stagionalità se il modello non riesce a calcolarla,
# ma con Apple la lasciamo attiva (gamma = NULL di default)
hw_fit <- HoltWinters(train_ts, seasonal = "additive")
# 3. Previsione per il Test Set
library(forecast)
hw_forecast <- forecast(hw_fit, h = length(test))
# 4. Estrazione Valori
pred_hw_train <- as.numeric(hw_fit$fitted[,1])
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# 5. Calcolo MSE
mse_hw <- mean((as.numeric(test) - pred_hw_test)^2)
pred_hw_test
################################################################################
# Phase 6: GAM MODEL
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Modello Holt-Winters (Senza stagionalità per massima velocità e stabilità)
# Nota: Spesso sui prezzi azionari il modello solo Trend (gamma=FALSE) performa meglio
hw_fit <- HoltWinters(train_ts, gamma = FALSE)
# 3. Previsione
library(forecast)
hw_for <- forecast(hw_fit, h = length(test))
# 4. GRAFICO VELOCE
plot(hw_for, main="Holt-Winters: Previsione vs Realtà",
col="blue", shadow=TRUE, ylab="Prezzo Apple ($)", xlab="Tempo")
# Aggiungiamo i dati reali sopra (Train + Test)
lines(as.numeric(all_price), col="black", lwd=1)
# Linea verticale che separa Train e Test
abline(v = length(train)/252 + 1, col="red", lty=2)
legend("topleft", legend=c("Prezzo Reale", "Previsione HW", "Intervallo Confidenza"),
col=c("black", "blue", "lightblue"), lwd=2, bty="n")
################################################################################
# Phase 6: GAM MODEL
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Modello Holt-Winters (Senza stagionalità per massima velocità e stabilità)
# Nota: Spesso sui prezzi azionari il modello solo Trend (gamma=FALSE) performa meglio
hw_fit <- HoltWinters(train_ts, gamma = FALSE)
# 3. Previsione
library(forecast)
hw_for <- forecast(hw_fit, h = length(test))
# 4. GRAFICO VELOCE
plot(hw_for, main="Holt-Winters: Previsione vs Realtà",
col="blue", shadow=TRUE, ylab="Prezzo Apple ($)", xlab="Tempo")
# Aggiungiamo i dati reali sopra (Train + Test)
lines(as.numeric(all_price), col="black", lwd=1)
# Linea verticale che separa Train e Test
abline(v = length(train)/252 + 1, col="red", lty=2)
legend("topleft", legend=c("Prezzo Reale", "Previsione HW", "Intervallo Confidenza"),
col=c("black", "blue", "lightblue"), lwd=2, bty="n")
################################################################################
library(gam)
t_train <- 1:length(train)
gam_data_train <- data.frame(y = as.numeric(train), t = t_train)
gam_data_test  <- data.frame(t = (length(train) + 1):n_obs)
################################################################################
# Phase 6: GAM MODEL
# 1. Preparazione Time Series (Frequenza 252)
train_ts <- ts(as.numeric(train), frequency = 252)
# 2. Fit del modello Holt-Winters (Base R)
# gamma = FALSE esclude la stagionalità se il modello non riesce a calcolarla,
# ma con Apple la lasciamo attiva (gamma = NULL di default)
hw_fit <- HoltWinters(train_ts, seasonal = "additive")
# 3. Previsione per il Test Set
library(forecast)
hw_forecast <- forecast(hw_fit, h = length(test))
# 4. Estrazione Valori
pred_hw_train <- as.numeric(hw_fit$fitted[,1])
# Nota: HoltWinters perde i primi osservazioni per il calcolo,
# quindi aggiungiamo dei NA iniziali per mantenere la lunghezza del train
pred_hw_train_full <- c(rep(NA, length(train) - length(pred_hw_train)), pred_hw_train)
pred_hw_test <- as.numeric(hw_forecast$mean)
# 5. Calcolo MSE
mse_hw <- mean((as.numeric(test) - pred_hw_test)^2)
cat("\n--- Risultati Holt-Winters ---\n")
cat("MSE Holt-Winters:", mse_hw, "\n")
################################################################################
library(gam)
### clearing the global environment
rm(list = ls())
##### temp some function I made in the past that could prove useful #####
aic.manual <- function(myarima, intord = 0, seasord = 0){
##temp notes: the function takes the actual data (time series) and then fits
## the arimas, so the input should NOT be an arima, but rather raw data
aicm <- matrix(0,4,4)
LowestIndex <- 0.0
MAIndex <- 0
ARIndex <- 0
for (i in 0:3) for (j in 0:3) {
fit<-arima(myarima, order = c(i,intord,j),
seasonal = list(order = c(0,seasord,0), period = 12), method = "ML")
aicm[i+1,j+1] <- fit$aic
if (i==0 & j==0) {
LowestIndex <- fit$aic
} else if (LowestIndex>aicm[i+1,j+1])  {
LowestIndex <- fit$aic
ARIndex <- i
MAIndex <- j
}
}
cat("Lowest Index =",LowestIndex, "\n")
cat("AR =",ARIndex, "\n")
cat("MA =",MAIndex, "\n")
rownames(aicm) <- c(0,1,2,3)
colnames(aicm) <- c(0,1,2,3)
aicm
}
int.conf <- function(fit.arima) {
cat("Upper Bound =", fit.arima$coef + (1.96 * diag(fit.arima$var.coef ^ 0.5)), "\n")
cat("Lower Bound =", fit.arima$coef - (1.96 * diag(fit.arima$var.coef ^ 0.5)), "\n")
}
#library requirement
if (!require("quantmod")) install.packages("quantmod")
if (!require("fpp2")) install.packages("fpp2")
if (!require("zoo")) install.packages("zoo")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("forecast")) install.packages("forecast")
if (!require("gam")) install.packages("gam")
if (!require("prophet")) install.packages("prophet")
library(quantmod)
library(zoo)
library(fpp2)
library(gridExtra)
library(urca)
library(forecast)
library(gam)
library(prophet)
symbol <- "AAPL"
data_fine <- as.Date("2026-01-01")
data_inizio <- data_fine - (365 * 5)
# getSymbols scarica automaticamente solo i giorni di borsa aperta
data_raw <- getSymbols(symbol, src = "yahoo", auto.assign = FALSE,
from = data_inizio, to = data_fine)
# Selezioniamo il prezzo rettificato ed eliminiamo eventuali NA residui
all_price <- na.omit(data_raw[, 6])
# Divisione train e test (80/20)
n_obs <- length(all_price)
split_point <- floor(0.8 * n_obs)
train <- all_price[1:split_point]
test  <- all_price[(split_point + 1):n_obs]
# Creazione serie storica con frequenza 252 (Standard finanziario)
# Non usiamo più 365 perché i weekend non esistono in questo dataset
train_set <- ts(as.numeric(train), frequency = 252)
test_set  <- ts(as.numeric(test), frequency = 252)
# Valori reali del test set per calcolo MSE
test_actual <- as.numeric(test)
# Plot dei dati reali (senza segmenti piatti nei weekend)
df_plot <- data.frame(
Data = index(all_price),
price = as.numeric(all_price),
type = c(rep("Train", length(train)), rep("Test", length(test)))
)
ggplot(df_plot, aes(x = Data, y = price, color = type)) +
geom_line(linewidth = 0.5) +
scale_color_manual(values = c("Train" = "#0072B2", "Test" = "#D55E00")) +
labs(title = "Apple Stock (AAPL) - Solo Giorni di Trading",
subtitle = "Frequenza annuale impostata a 252 giorni",
x = "Data", y = "Price Adjusted ($)") +
theme_minimal() +
scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
theme(legend.position = "bottom")
p1 <- autoplot(Acf(train_set, plot = FALSE, lag.max = 60)) +
ggtitle("ACF- Original") + theme_minimal()
p2 <- autoplot(Pacf(train_set, plot = FALSE, lag.max = 60)) +
ggtitle("PACF - Original") + theme_minimal()
grid.arrange(p1, p2)
#differentation of the series
diff_train <- diff(train_set)
p3 <- autoplot(Acf(diff_train, plot = FALSE, lag.max = 60)) +
ggtitle("ACF - Differentition") + theme_minimal()
p4 <- autoplot(Pacf(diff_train, plot = FALSE, lag.max = 60)) +
ggtitle("PACF - Differentition") + theme_minimal()
grid.arrange(p3, p4)
# 1. Stima del modello automatico
best_par <- aic.manual(train_set, intord = 1, seasord = 0)
fit_arima <- arima(train_set, order = c(0, 1, 0), method = "ML")
# 2. Diagnostica dei residui
checkresiduals(fit_arima)
# 3. Previsione sul test set
forecast_arima <- forecast(fit_arima, h = length(test))
pred_arima <- as.numeric(forecast_arima$mean)
# 4. Calcolo MSE
mse_arima <- mean((test_actual - pred_arima)^2)
cat("ARIMA AIC:", fit_arima$aic, "\n")
cat("ARIMA MSE:", mse_arima, "\n")
View(data_raw)
################################################################################
# Phase 4: Prophet Model
################################################################################
library(prophet)
df_prophet <- data.frame(ds = index(train), y  = as.numeric(train))
m_prophet <- prophet(df_prophet,
daily.seasonality = TRUE,
yearly.seasonality = TRUE,
weekly.seasonality = TRUE)
future <- make_future_dataframe(m_prophet, periods = length(test), freq = "day")
forecast_prophet <- predict(m_prophet, future)
# AIC (calcolo manuale dai residui training)
y_hat_train <- forecast_prophet$yhat[1:nrow(df_prophet)]
residuals_prophet <- df_prophet$y - y_hat_train
rss_prophet <- sum(residuals_prophet^2)
n <- nrow(df_prophet)
k_prophet <- sum(m_prophet$params$delta != 0) + 5
aic_prophet <- n * log(rss_prophet/n) + 2 * k_prophet
# MSE (su test set)
pred_prophet_test <- forecast_prophet$yhat[(n_obs - length(test) + 1):n_obs]
mse_prophet <- mean((test_actual - pred_prophet_test)^2)
aic_prophet
mse_prophet
################################################################################
# Phase 5: Diffusion Models (DIMORA)
################################################################################
library(DIMORA)
train_values <- as.numeric(train)
bm_model <- BM(train_values, display = FALSE)
summary(bm_model)
m_base <- 8.096008e+04
p_base <- 3.474946e-34
q_base <- 1.121650e+00
prelim_gbm <- c(m_base, p_base, q_base)
gbm_model <- GBM(train_values,  prelimestimates = prelim_gbm)
prelim_gbm <- c(m_base, p_base, q_base, 630, 750, 0,2)
gbm_model <- GBM(train_values, shock = "exp", nshock = 1,
prelimestimates = prelim_gbm)
summary(bm_model)
summary(gbm_model)
ggm_model <- GGM(train_values, prelimestimates = c(m_base, 0.001, 0.01,p_base,q_base), display = FALSE)
summary(ggm_model)
# Selezione AIC e Calcolo MSE per il vincitore
n_diff <- length(diff_train)
aic_bm <- n_diff * log(sum(residuals(bm_model)^2)/n_diff) + 2 * 3
aic_gbm <- n_diff * log(sum(residuals(gbm_model)^2)/n_diff) + 2 * length(gbm_model$pars)
n_test  <- length(test)
n_total <- n_train + n_test
indici_test <- (n_train + 1):n_total
pred_test_val <- predict(best_model, newx = indici_test)
pred_test <- as.numeric(pred_test_val)
mse_diffusion <- mean((as.numeric(test) - pred_test)^2)
cat("MSE sul Test Set:", mse_diffusion, "\n")
best_model <- ggm_model
################################################################################
# Phase 6: GAM MODEL
################################################################################
library(gam)
t_train <- 1:length(train)
gam_data_train <- data.frame(y = as.numeric(train), t = t_train)
gam_data_test  <- data.frame(t = (length(train) + 1):n_obs)
gam_1 <- gam(y ~ t, data = gam_data_train)
gam_2 <- gam(y ~ s(t, df=4), data = gam_data_train)
gam_3 <- gam(y ~ s(t, df=10), data = gam_data_train)
aic_gam <- min(AIC(gam_1), AIC(gam_2), AIC(gam_3))
best_gam <- list(gam_1, gam_2, gam_3)[[which.min(c(AIC(gam_1), AIC(gam_2), AIC(gam_3)))]]
# Previsione e MSE
pred_gam_test <- predict(best_gam, newdata = gam_data_test)
mse_gam <- mean((test_actual - as.numeric(pred_gam_test))^2)
modelli_nomi <- c("Auto-ARIMA", "Prophet", "Diffusion (Best)", "GAM (Best)")
aic_valori   <- c(fit_arima$aic, aic_prophet, best_aic_diff, aic_gam)
aic_ggm <- n_diff * log(sum(residuals(ggm_model)^2)/n_diff) + 2 * 5
aic_valori   <- c(fit_arima$aic, aic_prophet, aic_ggm, aic_gam)
mse_valori   <- c(mse_arima, mse_prophet, mse_diffusion, mse_gam)
best_model <- ggm_model
n_train <- length(train)
n_test  <- length(test)
n_total <- n_train + n_test
indici_test <- (n_train + 1):n_total
pred_test_val <- predict(best_model, newx = indici_test)
pred_test <- as.numeric(pred_test_val)
mse_diffusion <- mean((as.numeric(test) - pred_test)^2)
cat("MSE sul Test Set:", mse_diffusion, "\n")
modelli_nomi <- c("Auto-ARIMA", "Prophet", "Diffusion (Best)", "GAM (Best)")
aic_valori   <- c(fit_arima$aic, aic_prophet, aic_ggm, aic_gam)
mse_valori   <- c(mse_arima, mse_prophet, mse_diffusion, mse_gam)
performance_table <- data.frame(
Modello = modelli_nomi,
AIC = round(aic_valori, 2),
MSE = round(mse_valori, 2)
)
print("--- Performance Comparison Table ---")
print(performance_table)
# Prepariamo i vettori completi (Fitted + Forecast) per ogni modello
# ARIMA
fit_arima_full <- c(as.numeric(fitted(fit_arima)), pred_arima)
# Prophet
pred_prophet_full <- forecast_prophet$yhat
# Diffusion (già calcolato come pred_price_full)
pred_diff_full <- pred_price_full
# GAM
pred_gam_full <- c(as.numeric(fitted(best_gam)), as.numeric(pred_gam_test))
# Creazione del Grafico
plot(index(all_price), as.numeric(all_price), type="l", col="lightgray", lwd=2,
main="Comparison of Models: In-Sample Fit & Out-of-Sample Forecast",
ylab="Price ($)", xlab="Date")
# Aggiungiamo le linee dei modelli
lines(index(all_price), fit_arima_full, col="red", lwd=1, lty=1)       # ARIMA in Rosso
lines(index(all_price), pred_prophet_full, col="blue", lwd=1, lty=1)   # Prophet in Blu
lines(index(all_price), pred_diff_full, col="darkgreen", lwd=1, lty=1) # Diffusion in Verde
lines(index(all_price), pred_gam_full, col="purple", lwd=1, lty=1)     # GAM in Viola
# Linea verticale per indicare l'inizio del Test Set
abline(v=index(all_price)[split_point], col="black", lty=2, lwd=1.5)
text(index(all_price)[split_point], min(all_price), "Start Test Set", pos=4, cex=0.8)
# Legenda
legend("topleft",
legend=c("Actual Price", "Auto-ARIMA", "Prophet", "Diffusion (GGM)", "GAM"),
col=c("lightgray", "red", "blue", "darkgreen", "purple"),
lwd=2, bty="n", cex=0.8)
plot(index(test), test_actual, type="l", col="black", lwd=2,
main="Zoom: Test Set Forecasting Accuracy",
ylab="Price ($)", xlab="Date", ylim=c(min(test_actual)*0.9, max(test_actual)*1.1))
lines(index(test), pred_arima, col="red", lwd=2)
lines(index(test), pred_prophet_test, col="blue", lwd=2)
lines(index(test), pred_diffusion_test, col="darkgreen", lwd=2)
lines(index(test), pred_gam_test, col="purple", lwd=2)
legend("bottomleft",
legend=c("Actual", "ARIMA", "Prophet", "Diffusion", "GAM"),
col=c("black", "red", "blue", "darkgreen", "purple"),
lwd=2, bty="n", cex=0.8)
# GAM
pred_gam_full <- c(as.numeric(fitted(best_gam)), as.numeric(pred_gam_test))
# Creazione del Grafico
plot(index(all_price), as.numeric(all_price), type="l", col="lightgray", lwd=2,
main="Comparison of Models: In-Sample Fit & Out-of-Sample Forecast",
ylab="Price ($)", xlab="Date")
# Aggiungiamo le linee dei modelli
lines(index(all_price), fit_arima_full, col="red", lwd=1, lty=1)       # ARIMA in Rosso
lines(index(all_price), pred_prophet_full, col="blue", lwd=1, lty=1)   # Prophet in Blu
lines(index(all_price), pred_diff_full, col="darkgreen", lwd=1, lty=1) # Diffusion in Verde
lines(index(all_price), pred_gam_full, col="purple", lwd=1, lty=1)     # GAM in Viola
# Linea verticale per indicare l'inizio del Test Set
abline(v=index(all_price)[split_point], col="black", lty=2, lwd=1.5)
text(index(all_price)[split_point], min(all_price), "Start Test Set", pos=4, cex=0.8)
# Legenda
legend("topleft",
legend=c("Actual Price", "Auto-ARIMA", "Prophet", "Diffusion (GGM)", "GAM"),
col=c("lightgray", "red", "blue", "darkgreen", "purple"),
lwd=2, bty="n", cex=0.8)
plot(index(test), test_actual, type="l", col="black", lwd=2,
main="Zoom: Test Set Forecasting Accuracy",
ylab="Price ($)", xlab="Date", ylim=c(min(test_actual)*0.9, max(test_actual)*1.1))
lines(index(test), pred_arima, col="red", lwd=2)
lines(index(test), pred_prophet_test, col="blue", lwd=2)
lines(index(test), pred_diffusion_test, col="darkgreen", lwd=2)
lines(index(test), pred_gam_test, col="purple", lwd=2)
legend("bottomleft",
legend=c("Actual", "ARIMA", "Prophet", "Diffusion", "GAM"),
col=c("black", "red", "blue", "darkgreen", "purple"),
lwd=2, bty="n", cex=0.8)
